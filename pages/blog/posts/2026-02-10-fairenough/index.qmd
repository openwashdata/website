---
title: "Simplifying Research Data Sharing with R"
description: Introducing `fairenough`, an R package that streamlines the publication of FAIR-compliant data packages with minimal programming expertise.
categories:
    - open data
    - open science
    - research data
    - R
author: 
  - name: "Adriana Clavijo Daza"
    url: https://openwashdata.org/about/adriana/
    affiliation: Global Health Engineering, ETH Zurich
    affiliation_url: https://ghe.ethz.ch/
    orcid: 0009-0002-0589-2274
date: "2026-02-10"
draft: false
image: "OWD-logo-20.svg"
image-alt: "openwashdata logo"
---

```{r}
#| label: setup
#| include: false

# Set global options
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE
)

# Load required libraries
library(tidyverse)
library(robotoolbox)
library(readxl)
library(labelled)
library(here)

# Define OWD color palette
owd_palette <- c("#5b195b", "#9b2c60", "#ce525b",
                 "#f08453", "#ffbd54", "#f9f871")

background_color <- "#f5f5f2"
```

```{r}
#| label: load-data

source(here("pages",
            "blog",
            "posts",
            "2026-02-10-fairenough",
            "src", 
            "data_collection.R"))

form_id <- "ashaEDvw4ZLwGi9bqXGeqb"

form_file <- here("pages",
            "blog",
            "posts",
            "2026-02-10-fairenough",
            "data", 
            "registration_form.xlsx")

# fetch data from Kobo with robotoolbox
raw_data <- kobo_data(x = form_id,
                      all_versions = TRUE)

# read in questionnaire and labels from XLS form
questionnaire <- read_xlsx(form_file,
                           sheet = "survey")

label_dict <- read_xlsx(form_file,
                        sheet = "choices")
```

```{r}
#| label: data-processing
#| include: false

# Merge pre_survey and registration data
pre_survey_subset <- pre_survey |>
  select(data_storage = data_format) |>
  mutate(year = 2023)

registration_subset <- registration |>
  select(data_storage) |>
  mutate(year = 2025)

# Combine both datasets
combined_data <- bind_rows(pre_survey_subset, registration_subset) |>
  mutate(storage_type =
           case_when(
             str_detect(data_storage, "Google")   ~ "Spreadsheets",
             str_detect(data_storage, "database") ~ "Databases",
             str_detect(data_storage, "CSV")      ~ "Machine readable files",
             str_detect(data_storage, "paper")    ~ "Physically",
             TRUE                                 ~ "Other"
           )
  ) |>
  select(year, storage_type)

# Prepare programming experience data
prog_exp_2024 <- pre_survey |>
  select(prog_exp, prog_exp_r) |>
  mutate(year = 2023) |>
  rename(programming_experience = prog_exp,
         r_experience = prog_exp_r)

prog_exp_2025 <- registration |>
  select(programming_experience, r_experience) |>
  mutate(year = 2025)

# Combine programming experience data
combined_prog_exp <- bind_rows(prog_exp_2024, prog_exp_2025)

storage_order <- c("Spreadsheets",
                   "Machine readable files",
                   "Physically",
                   "Databases",
                   "Other") |> rev()

# Data preprocessing
storage_data <- combined_data |>
  filter(!is.na(storage_type)) |>
  count(year, storage_type) |>
  mutate(year = factor(year),
         storage_type = factor(storage_type,
                               levels = storage_order,
                               labels = storage_order,
                               ordered = TRUE))

prog_exp_order <- c("I have none.",
                    "I have written a few lines now and again.",
                    "I have written programs for my own use that are a couple of pages long.",
                    "I have written and maintained larger pieces of software.")

prog_exp_labels <- c("I have none.",
                     "I have written a few\nlines now and again.",
                     "I have written programs\nfor my own use that are a\ncouple of pages long.",
                     "I have written and\nmaintained larger pieces\nof software.")

# Reshape data to long format for combined plot
experience_long <- combined_prog_exp |>
  pivot_longer(cols = c(programming_experience, r_experience),
               names_to = "experience_type",
               values_to = "experience_level") |>
  filter(!is.na(experience_level)) |>
  count(year, experience_type, experience_level) |>
  mutate(year = factor(year),
         experience_level = factor(experience_level,
                                   levels = prog_exp_order,
                                   labels = prog_exp_labels,
                                   ordered = TRUE),
         experience_type = factor(experience_type,
                                  levels = c("programming_experience", "r_experience"),
                                  labels = c("Programming Overall", "R Programming")))
```

Working with Water, Sanitation, and Hygiene (WASH) researchers across multiple resource-limited countries, we observed that valuable datasets often remain underutilized. This is frequently due to limited familiarity with FAIR (**F**indable, **A**ccessible, **I**nteroperable, **R**eusable) data practices [(Wilkinson et al. 2016)](https://www.nature.com/articles/sdata201618). As part of the academic community, we recognize that research extends beyond traditional metrics like citations and publications. The demanding work of generating, collecting, and cleaning data frequently goes unrecognized, leaving many contributors unacknowledged. 
As part of GHE’s Open Science project [openwashdata](https://ghe.ethz.ch/open-science/projects/openwashdata.html) we conducted surveys with participants from our network of collaborators who were interested in participating in a [Data Science for Open WASH Data course](https://openwashdata.org/pages/academy/). The collected data reveals suboptimal data storage practices among WASH researchers, with many still relying on methods that hinder portability and interoperability (see @plot-storage).

```{r}
#| label: plot-storage
#| caption: "Data storage practices among WASH researchers"

storage_plot <- ggplot(storage_data, 
                       aes(y = storage_type, x = n, fill = year)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(y = "Storage Type",
       x = "Count",
       fill = "Year",
       title = "Data Storage Practices of WASH Researchers") +
  theme_minimal() +
  scale_fill_manual(values = owd_palette[c(1, 3)]) +
  theme(legend.position = "right",
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        plot.title = element_text(size = 16, face = "bold")) +
  theme(plot.background = element_rect(fill = background_color, color = NA),
        panel.background = element_rect(fill = background_color, color = NA)) 

print(storage_plot)
```

The survey data also shows varying levels of programming proficiency (see Figure @plot-experience), with many researchers having limited experience with R specifically. This highlights the need for user-friendly tools that don’t require extensive programming knowledge. A primary barrier is the lack of accessible tools that simplify data publication and distribution using open-source software. This challenge motivated the creation of [`washr`](https://cran.r-project.org/web/packages/washr/index.html), an R package that streamlines the process of transforming raw data into publication-ready data packages using devtools utilities.

```{r}
#| label: plot-experience
#| caption: "Programming experience among WASH researchers"
#| fig-width: 8
#| fig-height: 6

experience_plot <- ggplot(experience_long,
                          aes(y = experience_level, x = n, fill = year)) +
  geom_bar(stat = "identity", position = "stack") +
  facet_wrap(~experience_type) +
  labs(y = "",
       x = "Count",
       fill = "Year",
       title = "Programming Experience of WASH Researchers") +
  theme_minimal() +
  scale_fill_manual(values = owd_palette[c(1, 3)]) +
  theme(legend.position = "bottom",
        axis.text = element_text(size = 10),
        plot.title = element_text(size = 14, face = "bold"),
        strip.text = element_text(size = 12, face = "bold")) +
  theme(plot.background = element_rect(fill = background_color, color = NA),
        panel.background = element_rect(fill = background_color, color = NA))

print(experience_plot)
```

To complement `washr`, we developed a comprehensive [data publishing guide](https://global-health-engineering.github.io/ghedatapublishing/) as an online book using R and Quarto. This resource provides step-by-step instructions for creating data packages, including automated website generation where datasets are available for download in CSV and XLSX formats. The guide also covers version control with Git and GitHub, and DOI generation through Zenodo integration.

Following user feedback and recognizing the broader academic community’s need for accessible open data tools, we developed `fairenough`: an enhanced R package designed for more efficient data publishing workflows with minimal user input requirements. It provides a complete pipeline for R data package creation with the following features:

- **One-command pipeline:** Complete R data package creation with a single command featuring an automated and interactive workflow from tidy data to finished package and website.
- **Granular control options:** Individual wrapper functions with the alternative for overwriting documentation and optional detailed messages of the process in the console.

Compared with `washr` this new iteration minimizes the input required from users by reusing all the information provided when possible and suggesting content. For instance, `fairenough` leverages LLMs through [`ellmer`](https://ellmer.tidyverse.org/) to automatically generate data dictionaries. We also plan to provide a detailed guide for working with `fairenough`.

By automating metadata generation, ensuring proper documentation, enabling version control, and facilitating DOI assignment through Zenodo, `fairenough` directly addresses each component of the FAIR principles—making data **Findable** through comprehensive metadata, **Accessible** via the R data package and download options in the website, **Interoperable** by providing data and metadata in machine-readable formats, and **Reusable** with clear licensing and attribution.

We were thrilled to have the opportunity to present `fairenough` to the public last December at the [LatinR](https://latinr.org/) conference and received positive encouraging comments about this project. Our proposal was accepted as a lightning talk where we could demonstrate how to create an R data package and a website in a few minutes! We were lucky to share the (virtual) stage with other R enthusiasts who also presented interesting new tools. Discovering existing efforts for open science and reproducibility coming from different perspectives also enriches the development process of `fairenough`. It was especially motivating to participate in a space where we can reach and get feedback from Spanish and Portuguese speaking communities. We firmly believe that the lack of knowledge of open data and open science practices poses a significant barrier for their adoption and that’s why reaching a larger and more diverse audience has also become part of our mission.

### Resources:
- Learn how to get and get started with `fairenough`: [https://openwashdata.github.io/fairenough/](https://openwashdata.github.io/fairenough/)
- Slides of our lightning talk at LatinR: [https://openwashdata.org/pages/gallery/slides/#introducing-fairenough-at-latinr-2025](https://openwashdata.org/pages/gallery/slides/#introducing-fairenough-at-latinr-2025) 
- LatinR YouTube channel: [https://www.youtube.com/latinr](https://www.youtube.com/latinr) 
