
@misc{2020elife,
  title = {{{eLife}} Launches {{Executable Research Articles}} for Publishing Computationally Reproducible Results},
  year = {2020},
  month = aug,
  journal = {eLife},
  publisher = {{eLife Sciences Publications Limited}},
  abstract = {Authors with a published eLife paper can now enrich their work with embedded code blocks and computed outputs to make their results more transparent, interactive and reproducible.},
  copyright = {\textcopyright{} 2020 eLife Sciences Publications Limited. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited.},
  howpublished = {https://elifesciences.org/for-the-press/eb096af1/elife-launches-executable-research-articles-for-publishing-computationally-reproducible-results},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/XN3QPRPM/elife-launches-executable-research-articles-for-publishing-computationally-reproducible-results.html}
}

@misc{2022development,
  title = {Development {{Data Partnership}} - {{About}}},
  year = {2022},
  abstract = {A partnership between international organizations and companies, created to facilitate the use of third-party data in research and international development.},
  howpublished = {https://datapartnership.org/about/},
  file = {/Users/lschoebitz/Zotero/storage/NETE9G7X/about.html}
}

@article{abele-brehm2019attitudes,
  title = {Attitudes {{Toward Open Science}} and {{Public Data Sharing}}},
  author = {{Abele-Brehm}, Andrea E. and Gollwitzer, Mario and Steinberg, Ulf and Sch{\"o}nbrodt, Felix D.},
  year = {2019},
  month = jul,
  journal = {Social Psychology},
  volume = {50},
  number = {4},
  pages = {252--260},
  publisher = {{Hogrefe Publishing}},
  issn = {1864-9335},
  doi = {10.1027/1864-9335/a000384},
  abstract = {. Central values of science are, among others, transparency, verifiability, replicability, and openness. The currently very prominent Open Science (OS) movement supports these values. Among its most important principles are open methodology (comprehensive and useful documentation of methods and materials used), open access to published research output, and open data (making collected data available for re-analyses). We here present a survey conducted among members of the German Psychological Society (N~=~337), in which we applied a mixed-methods approach (quantitative and qualitative data) to assess attitudes toward OS in general and toward data sharing more specifically. Attitudes toward OS were distinguished into positive expectations (``hopes'') and negative expectations (``fears''). These were un-correlated. There were generally more hopes associated with OS and data sharing than fears. Both hopes and fears were highest among early career researchers and lowest among professors. The analysis of the open answers revealed that generally positive attitudes toward data sharing (especially sharing of data related to a published article) are somewhat diminished by cost/benefit considerations. The results are discussed with respect to individual researchers' behavior and with respect to structural changes in the research system.},
  keywords = {attitudes toward open science: data sharing hopes and data sharing fears,open science,public data sharing},
  file = {/Users/lschoebitz/Zotero/storage/BPPQBZ7M/Abele-Brehm et al. - 2019 - Attitudes Toward Open Science and Public Data Shar.pdf}
}

@misc{allaire2022quarto,
  title = {Quarto},
  author = {Allaire, J.J. and Teague, Charles and Scheidegger, Carlos and Xie, Yihui and Dervieux, Christophe},
  year = {2022},
  month = jan,
  doi = {10.5281/zenodo.5960048},
  abstract = {Open-source scientific and technical publishing system built on Pandoc.}
}

@article{arslan2019how,
  title = {How to {{Automatically Document Data With}} the Codebook {{Package}} to {{Facilitate Data Reuse}}},
  author = {Arslan, Ruben C.},
  year = {2019},
  month = jun,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {2},
  number = {2},
  pages = {169--187},
  publisher = {{SAGE Publications Inc}},
  issn = {2515-2459},
  doi = {10.1177/2515245919838783},
  abstract = {Data documentation in psychology lags behind not only many other disciplines, but also basic standards of usefulness. Psychological scientists often prefer to invest the time and effort that would be necessary to document existing data well in other duties, such as writing and collecting more data. Codebooks therefore tend to be unstandardized and stored in proprietary formats, and they are rarely properly indexed in search engines. This means that rich data sets are sometimes used only once\textemdash by their creators\textemdash and left to disappear into oblivion. Even if they can find an existing data set, researchers are unlikely to publish analyses based on it if they cannot be confident that they understand it well enough. My codebook package makes it easier to generate rich metadata in human- and machine-readable codebooks. It uses metadata from existing sources and automates some tedious tasks, such as documenting psychological scales and reliabilities, summarizing descriptive statistics, and identifying patterns of missingness. The codebook R package and Web app make it possible to generate a rich codebook in a few minutes and just three clicks. Over time, its use could lead to psychological data becoming findable, accessible, interoperable, and reusable, thereby reducing research waste and benefiting both its users and the scientific community as a whole.},
  langid = {english},
  keywords = {codebook,coding,data dictionary,data documentation,data visualization,individual differences,metadata,open materials,reliability},
  file = {/Users/lschoebitz/Zotero/storage/AI3X2ZVI/Arslan - 2019 - How to Automatically Document Data With the codebo.pdf}
}

@article{auer2021communityled,
  title = {A Community-Led Initiative for Training in Reproducible Research},
  author = {Auer, Susann and Haeltermann, Nele A and Weissberger, Tracey L and Erlich, Jeffrey C and Susilaradeya, Damar and Julkowska, Magdalena and Gazda, Ma{\l}gorzata Anna and Schwessinger, Benjamin and Jadavji, Nafisa M and {Reproducibility for Everyone Team}},
  editor = {P{\'e}rez Valle, Helena and Rodgers, Peter},
  year = {2021},
  month = jun,
  journal = {eLife},
  volume = {10},
  pages = {e64719},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.64719},
  abstract = {Open and reproducible research practices increase the reusability and impact of scientific research. The reproducibility of research results is influenced by many factors, most of which can be addressed by improved education and training. Here we describe how workshops developed by the Reproducibility for Everyone (R4E) initiative can be customized to provide researchers at all career stages and across most disciplines with education and training in reproducible research practices. The R4E initiative, which is led by volunteers, has reached more than 3000 researchers worldwide to date, and all workshop materials, including accompanying resources, are available under a CC-BY 4.0 license at https://www.repro4everyone.org/.},
  keywords = {lars,openscience,to-read},
  file = {/Users/lschoebitz/Zotero/storage/V6ZK2R5N/auer2021communityled.pdf}
}

@misc{azevedo2019introducing,
  title = {Introducing a {{Framework}} for {{Open}} and {{Reproducible Research Training}} ({{FORRT}})},
  author = {Azevedo, Flavio and Parsons, Sam and Micheli, Leticia and Strand, Julia and Rinke, Eike Mark and Guay, Samuel and Elsherif, Mahmoud and Quinn, Kimberly A. and Wagge, Jordan and Steltenpohl, Crystal N. and Kalandadze, Tamara and Vasilev, Martin Rachev and Oliveira, Catia Margarida and Aczel, Balazs and Miranda, Jacob Francisco and Baker, Bradley James and Galang, Carl Michael and Pennington, Charlotte Rebecca and Marques, Tamara and Laverty, Catherine and Liu, Meng and Weisberg, Yanna and Evans, Thomas Rhys and Pownall, Madeleine and Clark, Kait and {Albayrak-Aydemir}, Nihan and Westwood, Samuel and Hartmann, Helena and FORRT},
  year = {2019},
  month = dec,
  institution = {{OSF Preprints}},
  doi = {10.31219/osf.io/bnh7p},
  abstract = {Dramatic changes to the transparency, rigor, reproducibility and replicability of research practices have occurred in the last decade. Despite considerable progress towards the adoption of open science practices by researchers in many disciplines, developing pedagogy to train students in open and reproducible scholarship has received much less attention. Engaging students with the multiple dimensions of open scholarship is crucial to embedding sustainable change: it enables the future generation of researchers to practice open scholarship themselves, fosters lasting engagement with research, and allows them to better understand findings in light of epistemic uncertainty. Teaching students about open scholarship also helps it become a public good, thereby reducing knowledge inequities in academia and beyond. We address the lack of an infrastructure for open scholarship education by introducing the Framework for Open and Reproducible Research Training (FORRT). FORRT is a community-driven infrastructure for educators that advances research transparency, reproducibility, rigor, and ethics through pedagogical reform. FORRT encompasses multiple initiatives and tools to provide educators with guidance and resources to easily embed open and reproducible practices into research training. In addition to fostering a wider ecosystem for resource-sharing and discussion, FORRT has developed a wide range of initiatives, including a seven-part roadmap to the open scholarship literature, a curated database of open scholarship materials and pedagogies for customizable adoption by teachers, and a self-assessment tool to help educators evaluate the integration of open scholarship tenets in their own teaching and mentoring. FORRT actively works towards principled teaching and mentoring, an underappreciated dimension of the scientific endeavour.},
  langid = {american},
  file = {/Users/lschoebitz/Zotero/storage/LUANX8H5/azevedo2019introducing.pdf}
}

@misc{azevedo2021culture,
  title = {Towards a Culture of Open Scholarship: {{The}} Role of Pedagogical Communities},
  shorttitle = {Towards a Culture of Open Scholarship},
  author = {Azevedo, Flavio and Liu, Meng and Pennington, Charlotte Rebecca and Pownall, Madeleine and Evans, Thomas Rhys and Parsons, Sam and Elsherif, Mahmoud and Micheli, Leticia and Westwood, Samuel and FORRT},
  year = {2021},
  month = nov,
  institution = {{MetaArXiv}},
  doi = {10.31222/osf.io/ek9m5},
  abstract = {The UK House of Commons Science and Technology Committee has called for evidence on the roles that different stakeholders play in reproducibility and research integrity. Of central priority are proposals for improving research integrity and quality, as well as guidance and support for researchers. In response to this, we argue that there is one important component of research integrity that is often absent from discussion: the pedagogical consequences of how we teach, mentor, and supervise students through open scholarship. We justify the need to integrate open scholarship principles into research training within higher education and argue that pedagogical communities play a key role in fostering an inclusive culture of open scholarship. We illustrate these benefits by presenting A Framework for Open and Reproducible Research Training (FORRT), an international grassroots community whose goal is to provide support, resources, visibility, and advocacy for the adoption of principled, open teaching and mentoring practices, whilst generating conversations about the ethics and social impact of higher-education pedagogy. Representing a diverse group of early-career researchers and students across specialisms, we advocate for greater recognition of and support for pedagogical communities, and encourage all research stakeholders to engage with these communities to enable long-term, sustainable change.},
  langid = {american},
  file = {/Users/lschoebitz/Zotero/storage/4TC5ISRL/azevedo2021culture.pdf}
}

@book{baker2020reproducibility,
  title = {Reproducibility of Scientific Results in the {{EU}}: Scoping Report},
  shorttitle = {Reproducibility of Scientific Results in the {{EU}}},
  author = {Baker, Lee and Cristea, Ioana Alina and Errington, Timothy M. and Ja{\'s}ko, Katarzyna and Lusoli, Wainer and MacCallum, Catriona J. and Parry, Vivienne and P{\'e}rignon, Christophe and {\v S}imko, Tibor and Winchester, Catherine},
  year = {2020},
  publisher = {{Publications Office of the European Union}},
  address = {{LU}},
  abstract = {This report scopes the issue of the reproducibility of scientific results, based on a field review and on an expert seminar on the opportunity of policy action in Europe. As such, it aims to increase the European Commission's understanding of the lack of reproducibility in Europe, and help design a suitable response in the context of EU Research \& Innovation. The report identifies the key emerging issues in reproducibility; it is informed by clearly marked expert opinion (in italics), as it emerged from the scoping seminar. Concrete recommendations of possible action by the European Commission are featured in separate `Action Boxes'. Overall the report introduces the concept of reproducibility as a continuum of practices. It is posited that the reproducibility of results has value both as a mechanism to ensure good science based on truthful claims, and as a driver of further discovery and innovation. The sections includes a working definition that is conducive for policy making and thus delimits the scope of the subject. Then the report reviews recent claims regarding the increasing lack of reproducibility in modern science, dubbed by some a `crisis of reproducibility'. It explores the main traits and underlying causes of the lack of reproducibility, including bias, poor experimental design and statistics, issues with scientific reporting, research culture, career-related factors and economics. Finally, the report reviews recent activities by scientists, research funders and publishers that aim to mitigate the lack of reproducibility; and it catalogues a range of possible remedies to the lack of reproducibility as they are found in the literature. The report provides concrete advice for policy action that may increase reproducibility in three key areas of the EU Research \& Innovation, specifically guidelines; the research grant system; and training and careers},
  isbn = {978-92-76-19888-8},
  langid = {english},
  lccn = {KI-03-20-399-EN-N}
}

@article{beckman2021implementing,
  title = {Implementing {{Version Control With Git}} and {{GitHub}} as a {{Learning Objective}} in {{Statistics}} and {{Data Science Courses}}},
  author = {Beckman, Matthew D. and {\c C}etinkaya-Rundel, Mine and Horton, Nicholas J. and Rundel, Colin W. and Sullivan, Adam J. and Tackett, Maria},
  year = {2021},
  month = jan,
  journal = {Journal of Statistics and Data Science Education},
  volume = {29},
  number = {sup1},
  pages = {S132-S144},
  publisher = {{Taylor \& Francis}},
  issn = {null},
  doi = {10.1080/10691898.2020.1848485},
  abstract = {A version control system records changes to a file or set of files over time so that changes can be tracked and specific versions of a file can be recalled later. As such, it is an essential element of a reproducible workflow that deserves due consideration among the learning objectives of statistics courses. This article describes experiences and implementation decisions of four contributing faculty who are teaching different courses at a variety of institutions. Each of these faculty has set version control as a learning objective and successfully integrated one such system (Git) into one or more statistics courses. The various approaches described in the article span different implementation strategies to suit student background, course type, software choices, and assessment practices. By presenting a wide range of approaches to teaching Git, the article aims to serve as a resource for statistics and data science instructors teaching courses at any level within an undergraduate or graduate curriculum.},
  keywords = {lars,openscience,teaching},
  annotation = {\_eprint: https://doi.org/10.1080/10691898.2020.1848485},
  file = {/Users/lschoebitz/Zotero/storage/6ZJ44TK5/beckman2021implementing.pdf;/Users/lschoebitz/Zotero/storage/VF9H3VUY/10691898.2020.html}
}

@manual{boettiger2022dataspice,
  type = {Manual},
  title = {Dataspice: {{Create}} Lightweight {{Schema}}.Org Descriptions of Data},
  author = {Boettiger, Carl and Chamberlain, Scott and Fournier, Auriel and Hondula, Kelly and Krystalli, Anna and Mecum, Bryce and Salmon, Ma{\"e}lle and Webbink, Kate and Woo, Kara},
  year = {2022}
}

@article{broman2018data,
  title = {Data {{Organization}} in {{Spreadsheets}}},
  author = {Broman, Karl W. and Woo, Kara H.},
  year = {2018},
  month = jan,
  journal = {The American Statistician},
  volume = {72},
  number = {1},
  pages = {2--10},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2017.1375989},
  abstract = {Spreadsheets are widely used software tools for data entry, storage, analysis, and visualization. Focusing on the data entry and storage aspects, this article offers practical recommendations for organizing spreadsheet data to reduce errors and ease later analyses. The basic principles are: be consistent, write dates like YYYY-MM-DD, do not leave any cells empty, put just one thing in a cell, organize the data as a single rectangle (with subjects as rows and variables as columns, and with a single header row), create a data dictionary, do not include calculations in the raw data files, do not use font color or highlighting as data, choose good names for things, make backups, use data validation to avoid data entry errors, and save the data in plain text files.},
  keywords = {Data management,Data organization,Microsoft Excel,Spreadsheets},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2017.1375989},
  file = {/Users/lschoebitz/Zotero/storage/8MZ65GX8/Broman and Woo - 2018 - Data Organization in Spreadsheets.pdf;/Users/lschoebitz/Zotero/storage/NT8B67DR/00031305.2017.html}
}

@article{brown2018ten,
  title = {Ten Quick Tips for Teaching Programming},
  author = {Brown, Neil C. C. and Wilson, Greg},
  year = {2018},
  month = apr,
  journal = {PLOS Computational Biology},
  volume = {14},
  number = {4},
  pages = {e1006023},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006023},
  langid = {english},
  keywords = {Computer and information sciences,Computer software,Drag,Human learning,Instructors,Language,Language acquisition,Teachers},
  file = {/Users/lschoebitz/Zotero/storage/JFJZ2SAI/Brown and Wilson - 2018 - Ten quick tips for teaching programming.pdf}
}

@article{button2020grassroots,
  title = {Grassroots {{Training}} for {{Reproducible Science}}: {{A Consortium-Based Approach}} to the {{Empirical Dissertation}}},
  shorttitle = {Grassroots {{Training}} for {{Reproducible Science}}},
  author = {Button, Katherine S. and Chambers, Christopher D. and Lawrence, Natalia and Munaf{\`o}, Marcus R.},
  year = {2020},
  month = mar,
  journal = {Psychology Learning \& Teaching},
  volume = {19},
  number = {1},
  pages = {77--90},
  publisher = {{SAGE Publications}},
  issn = {1475-7257},
  doi = {10.1177/1475725719857659},
  abstract = {There is a widely acknowledged need to improve the reliability and efficiency of scientific research to increase the credibility of the published scientific literature and accelerate discovery. Widespread improvement requires a cultural shift in both thinking and practice, and better education will be instrumental to achieve this. Here we argue that education in reproducible science should start at the grassroots. We present our model of consortium-based student projects to train undergraduates in reproducible team science. We discuss how with careful design we have aligned collaboration with the current conventions for individual student assessment. We reflect on our experiences of several years running the GW4 Undergraduate Psychology Consortium offering insights we hope will be of practical use to others wishing to adopt a similar approach. We consider the pedagogical benefits of our approach in equipping students with 21st-century skills. Finally, we reflect on the need to shift incentives to reward to team science in global research and how this applies to the reward structures of student assessment.},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/RI5WM8CK/Button et al. - 2020 - Grassroots Training for Reproducible Science A Co.pdf}
}

@article{cacioppo2015social,
  title = {Social, Behavioral, and Economic Sciences Perspectives on Robust and Reliable Science},
  author = {Cacioppo, John T and Kaplan, Robert M and Krosnick, Jon A and Olds, James L and Dean, Heather},
  year = {2015},
  journal = {Report of the Subcommittee on Replicability in Science Advisory Committee to the National Science Foundation Directorate for Social, Behavioral, and Economic Sciences},
  file = {/Users/lschoebitz/Zotero/storage/T7BIY6IK/cacioppo2015social.pdf}
}

@article{cetinkaya-rundel2018infrastructure,
  title = {Infrastructure and {{Tools}} for {{Teaching Computing Throughout}} the {{Statistical Curriculum}}},
  author = {{\c C}etinkaya-Rundel, Mine and Rundel, Colin},
  year = {2018},
  month = jan,
  journal = {The American Statistician},
  volume = {72},
  number = {1},
  pages = {58--65},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2017.1397549},
  abstract = {Modern statistics is fundamentally a computational discipline, but too often this fact is not reflected in our statistics curricula. With the rise of big data and data science, it has become increasingly clear that students want, expect, and need explicit training in this area of the discipline. Additionally, recent curricular guidelines clearly state that working with data requires extensive computing skills and that statistics students should be fluent in accessing, manipulating, analyzing, and modeling with professional statistical analysis software. Much has been written in the statistics education literature about pedagogical tools and approaches to provide a practical computational foundation for students. This article discusses the computational infrastructure and toolkit choices to allow for these pedagogical innovations while minimizing frustration and improving adoption for both our students and instructors. Supplementary materials for this article are available online.},
  keywords = {lars,openscience,teaching,to-read},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2017.1397549},
  file = {/Users/lschoebitz/Zotero/storage/4AQXI2C7/Ã‡etinkaya-Rundel and Rundel - 2018 - Infrastructure and Tools for Teaching Computing Th.pdf;/Users/lschoebitz/Zotero/storage/KGNPHF83/00031305.2017.html}
}

@misc{community2019turing,
  title = {The {{Turing Way}}: {{A Handbook}} for {{Reproducible Data Science}}},
  shorttitle = {The {{Turing Way}}},
  author = {Community, The Turing Way and Arnold, Becky and Bowler, Louise and Gibson, Sarah and Herterich, Patricia and Higman, Rosie and Krystalli, Anna and Morley, Alexander and O'Reilly, Martin and Whitaker, Kirstie},
  year = {2019},
  month = mar,
  doi = {10.5281/zenodo.3233986},
  abstract = {Reproducible research is necessary to ensure that scientific work can be trusted. Funders and publishers are beginning to require that publications include access to the underlying data and the analysis code. The goal is to ensure that all results can be independently verified and built upon in future work. This is sometimes easier said than done. Sharing these research outputs means understanding data management, library sciences, software development, and continuous integration techniques: skills that are not widely taught or expected of academic researchers and data scientists. The Turing Way is a handbook to support students, their supervisors, funders and journal editors in ensuring that reproducible data science is "too easy not to do". It will include training material on version control, analysis testing, and open and transparent communication with future users, and build on Turing Institute case studies and workshops. This project is openly developed and any and all questions, comments and recommendations are welcome at our github repository: https://github.com/alan-turing-institute/the-turing-way. Release log v0.0.4: Continuous integration chapter merged to master. v0.0.3: Reproducible environments chapter merged to master. v0.0.2: Version control chapter merged to master. v0.0.1: Reproducibility chapter merged to master.},
  howpublished = {Zenodo},
  file = {/Users/lschoebitz/Zotero/storage/ZKX4IG99/3233986.html}
}

@article{devenyi2018ten,
  title = {Ten Simple Rules for Collaborative Lesson Development},
  author = {Devenyi, Gabriel A. and Emonet, R{\'e}mi and Harris, Rayna M. and Hertweck, Kate L. and Irving, Damien and Milligan, Ian and Wilson, Greg},
  year = {2018},
  month = mar,
  journal = {PLOS Computational Biology},
  volume = {14},
  number = {3},
  pages = {e1005963},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005963},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/BKCHTBTB/Devenyi et al. - 2018 - Ten simple rules for collaborative lesson developm.pdf;/Users/lschoebitz/Zotero/storage/PA5WSAXE/article.html}
}

@article{ellis2018how,
  title = {How to {{Share Data}} for {{Collaboration}}},
  author = {Ellis, Shannon E. and Leek, Jeffrey T.},
  year = {2018},
  month = jan,
  journal = {The American Statistician},
  volume = {72},
  number = {1},
  pages = {53--57},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2017.1375987},
  abstract = {Within the statistics community, a number of guiding principles for sharing data have emerged; however, these principles are not always made clear to collaborators generating the data. To bridge this divide, we have established a set of guidelines for sharing data. In these, we highlight the need to provide raw data to the statistician, the importance of consistent formatting, and the necessity of including all essential experimental information and pre-processing steps carried out to the statistician. With these guidelines we hope to avoid errors and delays in data analysis.},
  pmid = {32981941},
  keywords = {Analysis,Data sharing,Guidelines,Statistician,Tidy data},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2017.1375987},
  file = {/Users/lschoebitz/Zotero/storage/F4YV2AUM/00031305.2017.html}
}

@book{eth2011eth,
  title = {{{ETH Z\"urich Richtlinien}} F\"ur {{Integrit\"at}} in Der {{Forschung}} - {{Guidelines}} for Research Integrity},
  author = {ETH},
  year = {2011},
  file = {/Users/lschoebitz/Zotero/storage/WA6B7IHS/eth2011eth.pdf}
}

@misc{eth2020open,
  title = {Open {{Research Data}} \textendash{} {{ETH Board}}},
  author = {ETH},
  year = {2020},
  langid = {american},
  file = {/Users/lschoebitz/Zotero/storage/YY6XASQ7/ORD_Position_ETH_Domain.pdf;/Users/lschoebitz/Zotero/storage/ST2H23F5/open-research-data.html}
}

@article{fowler2018frictionless,
  title = {Frictionless {{Data}}: {{Making Research Data Quality Visible}}},
  shorttitle = {Frictionless {{Data}}},
  author = {Fowler, Dan and Barratt, Jo and Walsh, Paul},
  year = {2018},
  month = may,
  journal = {International Journal of Digital Curation},
  volume = {12},
  number = {2},
  publisher = {{University of Edinburgh}},
  issn = {1746-8256},
  doi = {10.2218/ijdc.v12i2.577},
  abstract = {DOAJ is a community-curated online directory that indexes and provides access to high quality, open access, peer-reviewed journals.},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/UHYEPA8J/Fowler et al. - 2018 - Frictionless Data Making Research Data Quality Vi.pdf}
}

@techreport{gather2020assessment,
  title = {An {{Assessment}} of the {{Sanitation Data Gap}} in {{Antananarivo}}, {{Madagascar}}},
  author = {Gather},
  year = {2020},
  file = {/Users/lschoebitz/Zotero/storage/U85NFUVA/Gather - 2020 - An Assessment of the Sanitation Data Gap in Antana.pdf}
}

@techreport{gather2020recommendations,
  title = {Recommendations for the Design of a Data Standard for Sanitation Data},
  author = {Gather},
  year = {2020},
  file = {/Users/lschoebitz/Zotero/storage/Q8UK7FT8/Gather - 2020 - Recommendations for the design of a data standard .pdf}
}

@misc{gsma2021innovative,
  title = {Innovative {{Data}} for {{Urban Planning}}: {{The Opportunities}} and {{Challenges}} of {{Public-Private Data Partnerships}}},
  shorttitle = {Innovative {{Data}} for {{Urban Planning}}},
  author = {GSMA},
  year = {2021},
  journal = {Mobile for Development},
  abstract = {Rapid urbanisation will be one of the most pressing and complex challenges in low-and-middle income countries (LMICs) for the next several decades. With cities in Africa and Asia expected to add more than one billion people, urban populations will represent two-thirds of the world population by 2050. This presents LMICs with an interesting opportunity and [\ldots ]},
  langid = {british},
  file = {/Users/lschoebitz/Zotero/storage/2ET9N6Q4/Innovative Data for Urban Planning The Opportunit.pdf;/Users/lschoebitz/Zotero/storage/IDFDV6DP/innovative-data-for-urban-planning-the-opportunities-and-challenges-of-public-private-data-part.html}
}

@article{johnston2021rcubed,
  title = {R-Cubed: {{Guiding}} the Overwhelmed Scientist from Random Wrangling to {{Reproducible Research}} in {{R}}},
  shorttitle = {R-Cubed},
  author = {Johnston, Luke W. and Juel, Helene Baek and Lengger, Bettina and Witte, Daniel R. and Chatwin, Hannah and Christiansen, Malene Revsbech and Isaksen, Anders Aasted},
  year = {2021},
  month = oct,
  journal = {Journal of Open Source Education},
  volume = {4},
  number = {44},
  pages = {122},
  issn = {2577-3569},
  doi = {10.21105/jose.00122},
  abstract = {Johnston et al., (2021). r-cubed: Guiding the overwhelmed scientist from random wrangling to Reproducible Research in R. Journal of Open Source Education, 4(44), 122, https://doi.org/10.21105/jose.00122},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/EPE6HBC2/johnston2021rcubed.pdf;/Users/lschoebitz/Zotero/storage/8ZUBEGMV/jose.html}
}

@misc{kathawalla2020easing,
  title = {Easing {{Into Open Science}}: {{A Guide}} for {{Graduate Students}} and {{Their Advisors}}},
  shorttitle = {Easing {{Into Open Science}}},
  author = {Kathawalla, Ummul-Kiram and Silverstein, Priya and Syed, Moin},
  year = {2020},
  month = may,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/vzjdp},
  abstract = {This article provides a roadmap to assist graduate students and their advisors to engage in open science practices. We suggest eight open science practices that novice graduate students could begin adopting today. The topics we cover include journal clubs, project workflow, preprints, reproducible code, data sharing, transparent writing, preregistration, and registered reports.},
  langid = {american},
  file = {/Users/lschoebitz/Zotero/storage/WZW2UQF4/Kathawalla et al. - 2020 - Easing Into Open Science A Guide for Graduate Stu.pdf}
}

@article{kowalczyk2022what,
  title = {What Senior Academics Can Do to Support Reproducible and Open Research: A Short, Three-Step Guide},
  shorttitle = {What Senior Academics Can Do to Support Reproducible and Open Research},
  author = {Kowalczyk, Olivia S. and Lautarescu, Alexandra and Blok, Elisabet and Dall'Aglio, Lorenza and Westwood, Samuel J.},
  year = {2022},
  month = mar,
  journal = {BMC Research Notes},
  volume = {15},
  number = {1},
  pages = {116},
  issn = {1756-0500},
  doi = {10.1186/s13104-022-05999-0},
  abstract = {Increasingly, policies are being introduced to reward and recognise open research practices, while the adoption of such practices into research routines is being facilitated by many grassroots initiatives. However, despite this widespread endorsement and support, as well as various efforts led by early career researchers, open research is yet to be widely adopted. For open research to become the norm, initiatives should engage academics from all career stages, particularly senior academics (namely senior lecturers, readers, professors) given their routine involvement in determining the quality of research. Senior academics, however, face unique challenges in implementing policy changes and supporting grassroots initiatives. Given that\textemdash like all researchers\textemdash senior academics are motivated by self-interest, this paper lays out three feasible steps that senior academics can take to improve the quality and productivity of their research, that also serve to engender open research. These steps include changing (a) hiring criteria, (b) how scholarly outputs are credited, and (c) how we fund and publish in line with~open research principles. The guidance we provide is accompanied by material for further reading.},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/NKVDG4HF/Kowalczyk et al. - 2022 - What senior academics can do to support reproducib.pdf}
}

@article{marwick2018packaging,
  title = {Packaging {{Data Analytical Work Reproducibly Using R}} (and {{Friends}})},
  author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
  year = {2018},
  month = jan,
  journal = {The American Statistician},
  volume = {72},
  number = {1},
  pages = {80--88},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2017.1375986},
  abstract = {Computers are a central tool in the research process, enabling complex and large-scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognizable way for organizing the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools.},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2017.1375986},
  file = {/Users/lschoebitz/Zotero/storage/V4WXZ5T2/Marwick et al. - 2018 - Packaging Data Analytical Work Reproducibly Using .pdf}
}

@article{mckiernan2016how,
  title = {How Open Science Helps Researchers Succeed},
  author = {McKiernan, Erin C and Bourne, Philip E and Brown, C Titus and Buck, Stuart and Kenall, Amye and Lin, Jennifer and McDougall, Damon and Nosek, Brian A and Ram, Karthik and Soderberg, Courtney K and Spies, Jeffrey R and Thaney, Kaitlin and Updegrove, Andrew and Woo, Kara H and Yarkoni, Tal},
  editor = {Rodgers, Peter},
  year = {2016},
  month = jul,
  journal = {eLife},
  volume = {5},
  pages = {e16800},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.16800},
  abstract = {Open access, open data, open source and other open scholarship practices are growing in popularity and necessity. However, widespread adoption of these practices has not yet been achieved. One reason is that researchers are uncertain about how sharing their work will affect their careers. We review literature demonstrating that open research is associated with increases in citations, media attention, potential collaborators, job opportunities and funding opportunities. These findings are evidence that open research practices bring significant benefits to researchers relative to more traditional closed practices.},
  file = {/Users/lschoebitz/Zotero/storage/I2BI4C99/McKiernan et al. - 2016 - How open science helps researchers succeed.pdf}
}

@book{miedema2022open,
  title = {Open {{Science}}: The {{Very Idea}}},
  shorttitle = {Open {{Science}}},
  author = {Miedema, Frank},
  year = {2022},
  publisher = {{Springer Nature}},
  doi = {10.1007/978-94-024-2115-6},
  abstract = {This open access book provides a broad context for the understanding of current problems of science and of the different movements aiming to improve the societal impact of science and research. The author offers insights with regard to ideas, old and new, about science, and their historical origins in philosophy and sociology of science, which is of interest to a broad readership. The book shows that scientifically grounded knowledge is required and helpful in understanding intellectual and political positions in various discussions on the grand challenges of our time and how science makes impact on society. The book reveals why interventions that look good or even obvious, are often met with resistance and are hard to realize in practice. Based on a thorough analysis, as well as personal experiences in aids research, university administration and as a science observer, the author provides - while being totally open regarding science's limitations- a realistic narrative about how research is conducted, and how reliable `objective' knowledge is produced. His idea of science, which draws heavily on American pragmatism, fits in with the global Open Science movement. It is argued that Open Science is a truly and historically unique movement in that it translates the analysis of the problems of science into major institutional actions of system change in order to improve academic culture and the impact of science, engaging all actors in the field of science and academia.},
  isbn = {978-94-024-2115-6},
  langid = {english},
  annotation = {Accepted: 2021-11-15T15:28:25Z},
  file = {/Users/lschoebitz/Zotero/storage/M7E43BXQ/miedema2022open.pdf}
}

@article{nederbragt2020ten,
  title = {Ten Quick Tips for Teaching with Participatory Live Coding},
  author = {Nederbragt, Alexander and Harris, Rayna Michelle and Hill, Alison Presmanes and Wilson, Greg},
  year = {2020},
  month = sep,
  journal = {PLOS Computational Biology},
  volume = {16},
  number = {9},
  pages = {e1008090},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008090},
  langid = {english},
  keywords = {Computer software,Eyes,Human learning,Instructors,Learning,Personal computers,Textbooks,Workshops},
  file = {/Users/lschoebitz/Zotero/storage/7QYI54S6/Nederbragt et al. - 2020 - Ten quick tips for teaching with participatory liv.pdf;/Users/lschoebitz/Zotero/storage/QU6JBVZE/article.html}
}

@article{ostblom2021opinionated,
  title = {Opinionated Practices for Teaching Reproducibility: Motivation, Guided Instruction and Practice},
  shorttitle = {Opinionated Practices for Teaching Reproducibility},
  author = {Ostblom, Joel and Timbers, Tiffany},
  year = {2021},
  month = sep,
  abstract = {In the data science courses at the University of British Columbia, we define data science as the study, development and practice of reproducible and auditable processes to obtain insight from data. While reproducibility is core to our definition, most data science learners enter the field with other aspects of data science in mind, for example predictive modelling, which is often one of the most interesting topic to novices. This fact, along with the highly technical nature of the industry standard reproducibility tools currently employed in data science, present out-of-the gate challenges in teaching reproducibility in the data science classroom. Put simply, students are not as intrinsically motivated to learn this topic, and it is not an easy one for them to learn. What can a data science educator do? Over several iterations of teaching courses focused on reproducible data science tools and workflows, we have found that providing extra motivation, guided instruction and lots of practice are key to effectively teaching this challenging, yet important subject. Here we present examples of how we deeply motivate, effectively guide and provide ample practice opportunities to data science students to effectively engage them in learning about this topic.},
  langid = {english},
  keywords = {lars,openscience,teaching,to-read},
  file = {/Users/lschoebitz/Zotero/storage/QGYXG8GA/ostblom2021opinionated.pdf;/Users/lschoebitz/Zotero/storage/NM4CLL38/2109.html}
}

@article{peng2011reproducible,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  author = {Peng, Roger D.},
  year = {2011},
  month = dec,
  journal = {Science},
  volume = {334},
  number = {6060},
  pages = {1226--1227},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.1213847},
  file = {/Users/lschoebitz/Zotero/storage/USVENB52/peng2011reproducible.pdf}
}

@article{peng2021reproducible,
  title = {Reproducible {{Research}}: {{A Retrospective}}},
  shorttitle = {Reproducible {{Research}}},
  author = {Peng, Roger D. and Hicks, Stephanie C.},
  year = {2021},
  month = apr,
  journal = {Annual Review of Public Health},
  volume = {42},
  pages = {79--93},
  issn = {1545-2093},
  doi = {10.1146/annurev-publhealth-012420-105110},
  abstract = {Advances in computing technology have spurred two extraordinary phenomena in science: large-scale and high-throughput data collection coupled with the creation and implementation of complex statistical algorithms for data analysis. These two phenomena have brought about tremendous advances in scientific discovery but have raised two serious concerns. The complexity of modern data analyses raises questions about the reproducibility of the analyses, meaning the ability of independent analysts to recreate the results claimed by the original authors using the original data and analysis techniques. Reproducibility is typically thwarted by a lack of availability of the original data and computer code. A more general concern is the replicability of scientific findings, which concerns the frequency with which scientific claims are confirmed by completely independent investigations. Although reproducibility and replicability are related, they focus on different aspects of scientific progress. In this review, we discuss the origins of reproducible research, characterize the current status of reproducibility in public health research, and connect reproducibility to current concerns about the replicability of scientific findings. Finally, we describe a path forward for improving both the reproducibility and replicability of public health research in the future.},
  langid = {english},
  pmid = {33467923},
  keywords = {data analysis,Data Analysis,Humans,Public Health,replicability,reproducibility,Reproducibility of Results,Research,Retrospective Studies},
  file = {/Users/lschoebitz/Zotero/storage/P3HM6QNX/Peng and Hicks - 2021 - Reproducible Research A Retrospective.pdf}
}

@article{plesser2018reproducibility,
  title = {Reproducibility vs. {{Replicability}}: {{A Brief History}} of a {{Confused Terminology}}},
  shorttitle = {Reproducibility vs. {{Replicability}}},
  author = {Plesser, Hans E.},
  year = {2018},
  journal = {Frontiers in Neuroinformatics},
  volume = {11},
  pages = {76},
  issn = {1662-5196},
  doi = {10.3389/fninf.2017.00076},
  file = {/Users/lschoebitz/Zotero/storage/3K4C5RRH/plesser2018reproducibility.pdf}
}

@misc{schobitz2021data,
  title = {Data {{Science}} for {{WASH}} Workshop Hosted at the {{Colorado WASH Symposium}} 2021},
  author = {Sch{\"o}bitz, Lars},
  year = {2021},
  month = feb,
  abstract = {This repository contains material of a workshop hosted at the Colorado WASH Symposium 2021.}
}

@misc{schobitz2022research,
  title = {Research {{Beyond}} the {{Lab}} \textendash{} {{Open Science}} and {{Research Methods}} for a {{Global Engineer}}},
  author = {Sch{\"o}bitz, Lars and Tilley, Elizabeth},
  year = {2022},
  howpublished = {https://rbtl-fs22.github.io/website/},
  file = {/Users/lschoebitz/Zotero/storage/ZUUPIVDD/website.html}
}

@misc{schwab2021ten,
  title = {Ten Simple Rules in Good Research Practice for Early Career Researchers},
  author = {Schwab, Simon and Janiaud, Perrine and Dayan, Michael and Amrhein, Valentin and Panczak, Radoslaw and Palagi, Patricia M. and Hemkens, Lars G. and Ramon, Meike and Rothen, Nicolas and Senn, Stephen and Furrer, Eva and Held, Leonhard},
  year = {2021},
  month = nov,
  institution = {{OSF Preprints}},
  doi = {10.31219/osf.io/am5ck},
  abstract = {This paper aims to provide early-career researchers with a useful introduction to good research practices.},
  langid = {american},
  keywords = {Medicine and Health Sciences,Social and Behavioral Sciences},
  file = {/Users/lschoebitz/Zotero/storage/NSVCGBCA/schwab2021ten.pdf}
}

@article{sciences2020roundtable,
  title = {Roundtable on Data Science Postsecondary Education: {{A}} Compilation of Meeting Highlights},
  author = {of Sciences, National Academies and {Engineering} and {Medicine} and others},
  year = {2020},
  publisher = {{National Academies Press}},
  keywords = {lars,to-read},
  file = {/Users/lschoebitz/Zotero/storage/TMVKJ2PI/2019 - Roundtable on Data Science Postsecondary Education.pdf}
}

@article{senyondo2021rdataretrievera,
  title = {Rdataretriever: {{R Interface}} to the {{Data Retriever}}},
  shorttitle = {Rdataretriever},
  author = {Senyondo, Henry and McGlinn, Daniel J. and Sharma, Pranita and Harris, David J. and Ye, Hao and Taylor, Shawn D. and Ooms, Jeroen and {Rodr{\'i}guez-S{\'a}nchez}, Francisco and Ram, Karthik and Pandey, Apoorva and Bansal, Harshit and Pohlman, Max and White, Ethan P.},
  year = {2021},
  month = jan,
  journal = {Journal of Open Source Software},
  volume = {6},
  number = {57},
  pages = {2800},
  issn = {2475-9066},
  doi = {10.21105/joss.02800},
  abstract = {Senyondo et al., (2021). Rdataretriever: R Interface to the Data Retriever. Journal of Open Source Software, 6(57), 2800, https://doi.org/10.21105/joss.02800},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/CELVD2LD/Senyondo et al. - 2021 - Rdataretriever R Interface to the Data Retriever.pdf}
}

@article{stoudt2021principles,
  title = {Principles for Data Analysis Workflows},
  author = {Stoudt, Sara and V{\'a}squez, V{\'a}leri N. and Martinez, Ciera C.},
  year = {2021},
  month = mar,
  journal = {PLOS Computational Biology},
  volume = {17},
  number = {3},
  pages = {e1008770},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008770},
  abstract = {A systematic and reproducible ``workflow''\textemdash the process that moves a scientific investigation from raw data to coherent research question to insightful contribution\textemdash should be a fundamental part of academic data-intensive research practice. In this paper, we elaborate basic principles of a reproducible data analysis workflow by defining 3 phases: the Explore, Refine, and Produce Phases. Each phase is roughly centered around the audience to whom research decisions, methodologies, and results are being immediately communicated. Importantly, each phase can also give rise to a number of research products beyond traditional academic publications. Where relevant, we draw analogies between design principles and established practice in software development. The guidance provided here is not intended to be a strict rulebook; rather, the suggestions for practices and tools to advance reproducible, sound data-intensive analysis may furnish support for both students new to research and current researchers who are new to data-intensive work.},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/9SN8IZ6M/stoudt2021principles.pdf;/Users/lschoebitz/Zotero/storage/P6UMEVAH/article.html}
}

@misc{swissnationalsciencefoundationsnsfopen,
  title = {Open {{Research Data}}: {{Which}} Data Repositories Can Be Used?},
  shorttitle = {Open {{Research Data}}},
  author = {Swiss National Science Foundation (SNSF)},
  journal = {Swiss National Science Foundation (SNSF)},
  abstract = {Swiss National Science Foundation (SNSF)},
  howpublished = {https://www.snf.ch/en/WtezJ6qxuTRnSYgF/topic/undefined/en/WtezJ6qxuTRnSYgF/topic/},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/IINJ4Y43/open-research-data-which-data-repositories-can-be-used.html}
}

@techreport{swissuniversities2021swissa,
  title = {Swiss {{National Open Research Data Strategy}}},
  author = {{swissuniversities}},
  year = {2021},
  file = {/Users/lschoebitz/Zotero/storage/G424C7QL/Swiss_National_ORD_Strategy_en.pdf}
}

@article{tierney2020realistic,
  title = {A {{Realistic Guide}} to {{Making Data Available Alongside Code}} to {{Improve Reproducibility}}},
  author = {Tierney, Nicholas J. and Ram, Karthik},
  year = {2020},
  month = feb,
  journal = {arXiv:2002.11626 [cs]},
  eprint = {2002.11626},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Data makes science possible. Sharing data improves visibility, and makes the research process transparent. This increases trust in the work, and allows for independent reproduction of results. However, a large proportion of data from published research is often only available to the original authors. Despite the obvious benefits of sharing data, and scientists' advocating for the importance of sharing data, most advice on sharing data discusses its broader benefits, rather than the practical considerations of sharing. This paper provides practical, actionable advice on how to actually share data alongside research. The key message is sharing data falls on a continuum, and entering it should come with minimal barriers.},
  archiveprefix = {arXiv},
  file = {/Users/lschoebitz/Zotero/storage/9BZR3FWY/tierney2020realistic.pdf;/Users/lschoebitz/Zotero/storage/4FBTSZBT/2002.html}
}

@article{wilkinson2016fair,
  title = {The {{FAIR Guiding Principles}} for Scientific Data Management and Stewardship},
  author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and {da Silva Santos}, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Merc{\`e} and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and {Gonzalez-Beltran}, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and {'t Hoen}, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and {Rocca-Serra}, Philippe and Roos, Marco and {van Schaik}, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and {van der Lei}, Johan and {van Mulligen}, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
  year = {2016},
  month = mar,
  journal = {Scientific Data},
  volume = {3},
  number = {1},
  pages = {160018},
  publisher = {{Nature Publishing Group}},
  issn = {2052-4463},
  doi = {10.1038/sdata.2016.18},
  abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders\textemdash representing academia, industry, funding agencies, and scholarly publishers\textemdash have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
  copyright = {2016 The Author(s)},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/XVE3XBLG/wilkinson2016fair.pdf;/Users/lschoebitz/Zotero/storage/ARFXMH5G/sdata201618.html}
}

@misc{wilson2019teaching,
  title = {Teaching {{Tech Together}}: {{How}} to {{Make Lessons That Work}} and {{Build}} a {{Teaching Community Around Them}}},
  shorttitle = {Teaching {{Tech Together}}},
  author = {Wilson, Greg},
  year = {2019},
  abstract = {Teaching Tech Together},
  howpublished = {Chapman \& Hall/CRC Press},
  isbn = {978-0-367-35297-4}
}

@misc{wpdx2022wpdx,
  title = {{{WPdx}} \textendash{} {{The Water Point Data Exchange}} Is the Global Platform for Sharing Water Point Data},
  author = {WPdx},
  year = {2022},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/PA8HYTSD/www.waterpointdata.org.html}
}


