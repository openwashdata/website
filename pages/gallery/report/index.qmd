---
title: "Untitled"
format: docx
---

# Lay summary (public, 1/2 page)

*Please summarize the objectives of the project, explain the progress achieved so far and – if applicable - the planned activities for the next period. This lay summary (maximum: ½ page) should be understandable by a non-expert audience and will be used for outreach and communications activities. By submitting this lay summary, you thus agree to making it potentially public.*

The vision of this project is to create an active global community that applies FAIR principles to data generated in the greater water, sanitation, and hygiene (WASH) sector. Current data management practices hold back progress which we address by empowering WASH professionals to engage with tools and workflows for open data and code. We introduce people to the concept of "open by default", as well as the use of open source software, the principles of open science, and benefits of open government (data). So far we have achieved to develop a data cleaning and publishing workflow using the R ecosystem and consistently applying the concepts and principles we teach. We are delivering a free online course with 10 modules for data science with R and expect 40 people to graduate from the course, applying the learned material to a real-life dataset of their own.

# Achievements (2 pages)

*Please describe the work conducted and what was achieved since the beginning of the project, referring to the planned objectives, milestones, and expected results described in the proposal (maximum: 2 pages). You should also explain how the project contributes to the wider aims of the ORD Explore programme (please refer to page 1 of the application guidelines for Contribute).*

This project consists of five work packages and 20 activities against which we will provide this report. The full name of each acitivity can be found in the activities table of the proposal: ttps://docs.google.com/spreadsheets/d/1T3NV75vVCeSRcN6FYghOrVFyWWi4WjQT5e4tqwp8jAQ/edit#gid=0).

**Contribution to ORD Explore programme aims.** This project significantly contributes to the overall aim of the program's measure 1 to assist researchers in becoming Open Science leaders in their fields. We are actively exploring/prototyping/building up ORD practices, and have been recognized for our efforts through being invited to speak at conferences and to collaborate with a journal to publish an opinion piece about open data in the WASH sector (in progress). The established ORD practices are fully transferable to scientific practices within the ETH-Domain and we actively promote our workflows in courses, committees, and a Data Stewardship Network established by the ETH Library.

## WP0: Infrastructure Design and Installation

::: callout-note
## Goal: The Goal of WP0 is to prototype a technical foundation for the ORD toolchain at ETH in a a way that allows teaching and scientific collaboration to continue beyond the explore project’s funding.

**Activity 0.1.** As the goal of this WP was to use technology that could be used beyond the explore project's funding, we decided to use Posit Cloud by Posit PBC, which is a cloud-based version of RStudio Server, instead of setting up Virtual Machines with ETH IT Services. The main advantage of Posit Cloud is that it is easier to set up and maintain than Virtual Machines. As an academic institution, we are eligible to an Instructor license for Posit Cloud, which allows unlimited shared spaces and projects. The cost of the Instructor license is 15 USD per month and during peak teaching activity in October we pay 50 USD for additional compute hours.

**Activity 0.2:** We decided to use the Matrix Protocol for communication. The main advantage of Matrix is that it is open source and decentralized. While the per user pricing models of software-as-a-service (SaaS) providers like Slack or Discord allow to use all of features without thinking of operating an own server, the underlying software is not open source nor do we have control over the data. Fortunately, ETH Zurich operates a so-called homeserver for the *matrix* network. This means that we can use the *matrix* network for secure, decentralized communication without having to operate our own server.

**Activity 0.3:** This activity is ongoing and will be completed by the end of the project.
:::

## WP1: Mobilize Community

::: callout-note
## Goal: Create and grow an international network of data-curious practitioners and students who may be interested in pursuing one or more of the subsequent activities.

**Activity 1.1.** We advertised the opportunities to contribute to the openwashdata community at three conferences, two of which with accepted abstracts for presentation and a side event. Beyond this, we have actively used the Global Health Engineering LinkedIn account (\> 1600 followers as of December 2023) to advertise for the openwashdata community. However, our main activity to advertise the openwashdata community was to develop and teach 10-week synchronous online course (more info under WP3.

**Activity 1.2.** We have not hosted any live coding events yet. While we expected that hosting such events would be straightforward, we have not given it priority over other activities.
:::

## WP2: Data sharing

::: callout-note
## Goal: Solicit and receive interest in providing data to be published openly; develop an easy-to-use data-collection protocol and tool; receive data from interested partners.

**Activity 2.1.** The goal of this activity was to streamline the data sharing and publishing process. Instead of using a GitHub repository template we have decided to utilize existing templates for R packages to publish all datasets. R has a rich ecosystem for documenting functions which can also be used for documenting datasets. R packages exist that reduce the workload of documenting datasets to a minimum and allow for visually attractive outputs. Each dataset receives a unique DOI using Zenodo and the data package is published using GitHub Pages. Any R user can install the data package using a single command and we further provide the cleaned data as a CSV and XLSX to allow for use in other software.

**Activity 2.2.** This activity is ongoing and we have not yet reached out to all pre-identified sources from the proposal. Reasons include that we are slower than expected in documenting and publishing datasets, but also have realized that people with an existing motivation to share their data have found us and we can hold back on reaching out to others until we have published the datasets we have already received.

**Activity 2.3.** We have provided instructions for joining the openwashdata community on Element using the Matrix Chat and have published a blog post with a starter kit to become a part of the openwashdata community. At this point, we have focused our efforts on building a community of like-minded people and to teach the tools we use for our publishing process.
:::

## WP3: Data cleaning

::: callout-note
## Goal: Facilitate user-directed data cleaning (including documentation and metadata) to produce a first set of analysis-ready open datasets

**Activity 3.1.** We have not yet invited openwashdata community members to contribute to data cleaning activities, however graduates from our first "data science for openwashdata" course are actively performing such tasks for their own data and we intend to publish the datasets using our workflow.

**Activity 3.2.** We use GitHub labels to categorize data sources into rubrics of "effort for cleaning" and "impact of clean data", however, we have also realized that this estimate is rather objective and that we need to work with the data to get a better understanding of the effort required to clean the data.

**Activity 3.3.** We are currently teaching a 10-week synchronous online course (2.5 hours per week) for openwashdata community members to learn the competencies needed to clean submitted data. We had 210 registrations, of which 110 showed up for the first module, and we anticipate 40 graduates in February 2024. Each graduate will prepare a final capstone project report with their own data and publish it openly using GitHub Pages. We will invite everyone to work with us on publishing their data using our defined data publishing workflow.

**Activity 3.4:** We have not yet hosted any online hackathons, but are planning to do so in the final quarter of the projects duration. 

**Activity 3.5:** We have not provided an in-person workshop at a sector relevant conference and are re-considering if this effort is better spent on teaching online advanced online courses.
:::

## WP4: Data publishing and communication

::: callout-note
## Goal: Increase reach and impact of data by making it citable and creating data communication products

**Activity 4.1.** We have completed the publication of eight datasets and have another seven under active development. Our long list of datasets contains an additional 15 datasets. The archived GitHub repositories contain the original unprocessed (raw) data, the processed analysis-ready data, and the code to get from the raw to analysis-ready, ensuring reproducibility and allowing others to verify the correctness of our data cleaning process. All of this is archived on Zenodo for long-term storage and to receive a DOI for each dataset.

**Activity 4.2.** We have opted for using the `pkgdown` R package to develop and build websites for each dataset. Each landing page uses one refined data visualization to communicate the key insights of the dataset, followed by a short description of the dataset, and a list of all variables and their description. For each dataset, we prepare additional analysis and data visualizations to showcase how R can be used with the data to produce data communication products. The code is shared alongside the output, so that it can copied into a users environment for further exploration.

**Activity 4.3.** Instead doing preparing R packages for selected datasets only, we have opted for publishing all datasets as R data packages. This allows us to use the same process for all datasets and to ensure that all datasets are published in a consistent manner.

**Activity 4.4.** We have setup an additional metadata table for all datasets from which we publish a data catalogue on our main website. In the future, we intend to enrich this metadata table with further information and exploring additional metadata standards that we can use to describe our datasets and publish them in formats that increase discoverability and reuse.
:::

# Deviations from original plan ()

*Please describe and justify any major changes or deviations from the original plan as set out in the application form (e.g. expected results and objectives), notably unexpected challenges/problems (or unforeseen/unexpected positive outcomes) and how they have been addressed. Events such as changes of personnel, changes in the financial resources’ usage plan and delayed start of project must be mentioned and – if needed – agreed in advance. If applicable, the implications and impact for the 2nd phase of the project must also be described.*

We have had no major deviations from the original plan. More challenging than expected is the interaction with people that provide datasets or that we have identified as potential sources of datasets. In our workflow we have deviated from working with GitHub issues and have reverted largely to email for communication with people that are not yet familiar with GitHub. The most challenging part of the process is to get a complete description of all variables, especially for datasets that are surveys have have 100s of variables which are acronyms.

While we had always expected that the planned data science course would meet high demand, we did not foresee such a large number of participants to follow through the course in all modules, submitting homework assignments and intending to complete the capstone project report. Strategically, the capstone project report is the only requirement that we have to receive a certificate of completion. This is independent of the number of classes that were attended or homework assignments completed. We believe that without class attendance, a completion of the capstone report would be feasible, unless participants already had enough prior knowledge. We therefore expect about 30 to 40 public project reports using real-life data that participants identified themselves. This effort will have a significant impact on the community and beyond as we have a cohort of 40 graduates that have worked with real-life data and have learned the tools and skills to clean and analyze data.

Another unexpected positive outcome is the effect of the course on networking and community building. While we intentionally developed lesson plans which include 45 minutes (1/3 of total) of work in break-out rooms with 3 to 4 participants, we did not expect that this would lead to such a strong sense of community. We have observed that participants have started to work together on their homework assignments and exchange contact details to connect beyond the course.

# Value delivered for ORD practices/communities

*Please explain the impact (achieved or expected) of the project and ORD practices on new or existing ORD communit(ies) during and beyond the funding period, including on the wider ETH Domain. Please explain whether the project will continue and if so, how it will be sustained. Please also describe the main outreach and dissemination activities undertaken and/or planned.*

The short-term impact of the on ORD practices in the WASH community is that we equipped 40 participants with the skills and tools to work reproducibly with data and code. We expect that these participants will continue to work with data and code and that they will share their knowledge with others. It has impact on each organization that these 40 participants work for and we expect a domino effect that will attract more people to join our course in the future and actively invest into ORD practices. The long-term impact will become visible as more WASH researchers will publish their data alongside scientific articles, which are able to verify as we currently work on an article with an analysis of current ORD practices.

The ORD practices that were developed for the openwashdata community have also established themselves within the research practice of the Global Health Engineering group and partners. Workflows and tools will continuously be refined, so that they remain transferable to other disciplines and communities, benefiting the wider ETH Domain.

To continue building the community, we are working on securing additional funding through the 2nd Explore call of the ETH Board. We have further started partnerships with like-minded organizations and are exploring how we can work together to increase the sustainability of our work and the project. And even without third-party funding, we will be able to sustain our work as we can leverage the existing expertise infrastructure of the Global Health Engineering group and partners.

# List of Outputs

*Please indicate the outputs directly related to this ORD project since it began and provide further details in the table below, if and as applicable.*

The table below can be accessed online as a Google Sheet here: https://docs.google.com/spreadsheets/d/194Lv5Ui0bnr-tUhWC-r2pz0gWaPW4yuBqUr_eILOKkE/edit#gid=0

# Appendix

Please attach any additional documentation relevant to the ORD project (e.g. screenshots, resources developed, outreach material, copies/link to publications etc.).
